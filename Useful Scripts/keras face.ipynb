{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"conv1_1\", activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"conv1_2\", activation=\"relu\")`\n",
      "  \n",
      "/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"conv2_1\", activation=\"relu\")`\n",
      "/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"conv2_2\", activation=\"relu\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_11/MaxPool' (op: 'MaxPool') with input shapes: [?,1,112,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_11/MaxPool' (op: 'MaxPool') with input shapes: [?,1,112,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7f5b04b129d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Test pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/saadi/Learningfolder/vgg-face-keras.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7f5b04b129d9>\u001b[0m in \u001b[0;36mvgg_face\u001b[0;34m(weights_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpad2_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mconv2_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv2_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad2_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mpool2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpad3_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    156\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    219\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    220\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   3653\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3654\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3655\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1767\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1769\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m_max_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1603\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool\", input=input, ksize=ksize,\n\u001b[1;32m   1604\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   1606\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saadi/.virtualenvs/keras-pyth3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_11/MaxPool' (op: 'MaxPool') with input shapes: [?,1,112,128]."
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dropout, Activation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def vgg_face(weights_path=None):\n",
    "    img = Input(shape=(3, 224, 224))\n",
    "\n",
    "    pad1_1 = ZeroPadding2D(padding=(1, 1))(img)\n",
    "    conv1_1 = Convolution2D(64, 3, 3, activation='relu', name='conv1_1')(pad1_1)\n",
    "    pad1_2 = ZeroPadding2D(padding=(1, 1))(conv1_1)\n",
    "    conv1_2 = Convolution2D(64, 3, 3, activation='relu', name='conv1_2')(pad1_2)\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2))(conv1_2)\n",
    "\n",
    "    pad2_1 = ZeroPadding2D((1, 1))(pool1)\n",
    "    conv2_1 = Convolution2D(128, 3, 3, activation='relu', name='conv2_1')(pad2_1)\n",
    "    pad2_2 = ZeroPadding2D((1, 1))(conv2_1)\n",
    "    conv2_2 = Convolution2D(128, 3, 3, activation='relu', name='conv2_2')(pad2_2)\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2))(conv2_2)\n",
    "\n",
    "    pad3_1 = ZeroPadding2D((1, 1))(pool2)\n",
    "    conv3_1 = Convolution2D(256, 3, 3, activation='relu', name='conv3_1')(pad3_1)\n",
    "    pad3_2 = ZeroPadding2D((1, 1))(conv3_1)\n",
    "    conv3_2 = Convolution2D(256, 3, 3, activation='relu', name='conv3_2')(pad3_2)\n",
    "    pad3_3 = ZeroPadding2D((1, 1))(conv3_2)\n",
    "    conv3_3 = Convolution2D(256, 3, 3, activation='relu', name='conv3_3')(pad3_3)\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2))(conv3_3)\n",
    "\n",
    "    pad4_1 = ZeroPadding2D((1, 1))(pool3)\n",
    "    conv4_1 = Convolution2D(512, 3, 3, activation='relu', name='conv4_1')(pad4_1)\n",
    "    pad4_2 = ZeroPadding2D((1, 1))(conv4_1)\n",
    "    conv4_2 = Convolution2D(512, 3, 3, activation='relu', name='conv4_2')(pad4_2)\n",
    "    pad4_3 = ZeroPadding2D((1, 1))(conv4_2)\n",
    "    conv4_3 = Convolution2D(512, 3, 3, activation='relu', name='conv4_3')(pad4_3)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4_3)\n",
    "\n",
    "    pad5_1 = ZeroPadding2D((1, 1))(pool4)\n",
    "    conv5_1 = Convolution2D(512, 3, 3, activation='relu', name='conv5_1')(pad5_1)\n",
    "    pad5_2 = ZeroPadding2D((1, 1))(conv5_1)\n",
    "    conv5_2 = Convolution2D(512, 3, 3, activation='relu', name='conv5_2')(pad5_2)\n",
    "    pad5_3 = ZeroPadding2D((1, 1))(conv5_2)\n",
    "    conv5_3 = Convolution2D(512, 3, 3, activation='relu', name='conv5_3')(pad5_3)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5_3)\n",
    "\n",
    "    fc6 = Convolution2D(4096, 7, 7, activation='relu', name='fc6')(pool5)\n",
    "    fc6_drop = Dropout(0.5)(fc6)\n",
    "    fc7 = Convolution2D(4096, 1, 1, activation='relu', name='fc7')(fc6_drop)\n",
    "    fc7_drop = Dropout(0.5)(fc7)\n",
    "    fc8 = Convolution2D(2622, 1, 1, name='fc8')(fc7_drop)\n",
    "    flat = Flatten()(fc8)\n",
    "    out = Activation('softmax')(flat)\n",
    "\n",
    "    model = Model(input=img, output=out)\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    im = Image.open('/home/saadi/Desktop/test_xml _write/images/0.jpg')\n",
    "    im = im.resize((224,224))\n",
    "    im = np.array(im).astype(np.float32)\n",
    "#    im[:,:,0] -= 129.1863\n",
    "#    im[:,:,1] -= 104.7624\n",
    "#    im[:,:,2] -= 93.5940\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "\n",
    "    # Test pretrained model\n",
    "    model = vgg_face('/home/saadi/Learningfolder/vgg-face-keras.h5')\n",
    "    out = model.predict(im)\n",
    "    print(out[0][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### FAce recognition model##############\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############### Vgg Face\n",
    "\n",
    "def vgg_face(weights_path=None):\n",
    "    img = Input(shape=(3, 224, 224))\n",
    "\n",
    "    pad1_1 = ZeroPadding2D(padding=(1, 1))(img)\n",
    "    conv1_1 = Convolution2D(64, 3, 3, activation='relu', name='conv1_1')(pad1_1)\n",
    "    pad1_2 = ZeroPadding2D(padding=(1, 1))(conv1_1)\n",
    "    conv1_2 = Convolution2D(64, 3, 3, activation='relu', name='conv1_2')(pad1_2)\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2))(conv1_2)\n",
    "\n",
    "    pad2_1 = ZeroPadding2D((1, 1))(pool1)\n",
    "    conv2_1 = Convolution2D(128, 3, 3, activation='relu', name='conv2_1')(pad2_1)\n",
    "    pad2_2 = ZeroPadding2D((1, 1))(conv2_1)\n",
    "    conv2_2 = Convolution2D(128, 3, 3, activation='relu', name='conv2_2')(pad2_2)\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2))(conv2_2)\n",
    "\n",
    "    pad3_1 = ZeroPadding2D((1, 1))(pool2)\n",
    "    conv3_1 = Convolution2D(256, 3, 3, activation='relu', name='conv3_1')(pad3_1)\n",
    "    pad3_2 = ZeroPadding2D((1, 1))(conv3_1)\n",
    "    conv3_2 = Convolution2D(256, 3, 3, activation='relu', name='conv3_2')(pad3_2)\n",
    "    pad3_3 = ZeroPadding2D((1, 1))(conv3_2)\n",
    "    conv3_3 = Convolution2D(256, 3, 3, activation='relu', name='conv3_3')(pad3_3)\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2))(conv3_3)\n",
    "\n",
    "    pad4_1 = ZeroPadding2D((1, 1))(pool3)\n",
    "    conv4_1 = Convolution2D(512, 3, 3, activation='relu', name='conv4_1')(pad4_1)\n",
    "    pad4_2 = ZeroPadding2D((1, 1))(conv4_1)\n",
    "    conv4_2 = Convolution2D(512, 3, 3, activation='relu', name='conv4_2')(pad4_2)\n",
    "    pad4_3 = ZeroPadding2D((1, 1))(conv4_2)\n",
    "    conv4_3 = Convolution2D(512, 3, 3, activation='relu', name='conv4_3')(pad4_3)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4_3)\n",
    "\n",
    "    pad5_1 = ZeroPadding2D((1, 1))(pool4)\n",
    "    conv5_1 = Convolution2D(512, 3, 3, activation='relu', name='conv5_1')(pad5_1)\n",
    "    pad5_2 = ZeroPadding2D((1, 1))(conv5_1)\n",
    "    conv5_2 = Convolution2D(512, 3, 3, activation='relu', name='conv5_2')(pad5_2)\n",
    "    pad5_3 = ZeroPadding2D((1, 1))(conv5_2)\n",
    "    conv5_3 = Convolution2D(512, 3, 3, activation='relu', name='conv5_3')(pad5_3)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5_3)\n",
    "\n",
    "    flat = Flatten()(pool5)\n",
    "    fc6 = Dense(4096, activation='relu', name='fc6')(flat)\n",
    "    fc6_drop = Dropout(0.5)(fc6)\n",
    "    fc7 = Dense(4096, activation='relu', name='fc7')(fc6_drop)\n",
    "    fc7_drop = Dropout(0.5)(fc7)\n",
    "out = Dense(2622, activation='softmax', name='fc8')(fc7_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 2.2304\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2422\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2470\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2376\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2449\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2393\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2468\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2377\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2449\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2395\n",
      "20/20 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-be3f8c7f86da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# decode the results into a list of tuples (class, description, probability)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "plot_model(model, to_file='shared_input_layer.png')\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "\n",
    "def residual_block(y, nb_channels, _strides=(1, 1), _project_shortcut=False):\n",
    "    shortcut = y\n",
    "\n",
    "    # down-sampling is performed with a stride of 2\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "\n",
    "    # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "    if _project_shortcut or _strides != (1, 1):\n",
    "        # when the dimensions increase projection shortcut is used to match dimensions (done by 1Ã—1 convolutions)\n",
    "        # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "        shortcut = layers.Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    y = layers.add([shortcut, y])\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    return y\n",
    "model = Model(inputs=Input_image, outputs=output)\n",
    "# summarize layers\n",
    "print(model.summary())\n",
    "# plot graph\n",
    "plot_model(model, to_file='shared_input_layer.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
